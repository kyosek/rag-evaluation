{
  "overall_stats": {
    "avg_difficulty": 0.4643721336298122,
    "avg_discrimination": 1.073300962003061,
    "avg_guessing": 0.2527249054246911,
    "avg_feasibility": 0.8117517888459956,
    "total_questions": 340
  },
  "hop_analysis": {
    "1": {
      "avg_difficulty": 0.4238117071524387,
      "avg_discrimination": 1.083836220139177,
      "avg_guessing": 0.2752025108683787,
      "avg_feasibility": 0.7811774232534501,
      "num_questions": 150
    },
    "2": {
      "avg_difficulty": 0.49655361273179227,
      "avg_discrimination": 1.0532342497180194,
      "avg_guessing": 0.2166251276319684,
      "avg_feasibility": 0.724654024187146,
      "num_questions": 72
    },
    "3": {
      "avg_difficulty": 0.6267750871304594,
      "avg_discrimination": 1.0573013903153066,
      "avg_guessing": 0.16265237933087492,
      "avg_feasibility": 0.7075054011573294,
      "num_questions": 42
    },
    "4": {
      "avg_difficulty": 0.4223755029307893,
      "avg_discrimination": 1.0478043298751936,
      "avg_guessing": 0.24152714453933385,
      "avg_feasibility": 0.7367080639347074,
      "num_questions": 39
    },
    "5": {
      "avg_difficulty": 0.42610029650814135,
      "avg_discrimination": 1.1146756978943595,
      "avg_guessing": 0.2527249054246911,
      "avg_feasibility": 0.8117517888459956,
      "num_questions": 37
    }
  },
  "model_abilities": {
    "llama3-8b_DenseV3": 1.350768026573601,
    "llama3-8b_DenseV4": 1.2038858844991438,
    "llama3-8b_SparseV3": 1.3160125729439158,
    "llama3-8b_HybridV3": 1.3727908033531766,
    "llama3-8b_RerankV3": 1.4550279973176838,
    "llama3-8b_DenseV5-5": 0.954498908702783,
    "llama3-8b_SparseV5-5": 0.7614125602236977,
    "llama3-8b_HybridV5-5": 0.850776929010481,
    "llama3-8b_RerankV5-5": 1.2575592394388444,
    "llama3-8b_DenseV5-10": 1.2412582403938668,
    "llama3-8b_SparseV5-10": 0.7191205084109509,
    "llama3-8b_HybridV5-10": 1.2758178411007246,
    "llama3-8b_RerankV5-10": 1.2708102910633419,
    "llama3-8b_open_book": 1.2767452136325026,
    "mistral-8b_DenseV3": 1.7271598055395787,
    "mistral-8b_SparseV3": 1.6924043519098935,
    "mistral-8b_HybridV3": 1.7491825823191542,
    "mistral-8b_RerankV3": 1.8314197762836615,
    "mistral-8b_DenseV5-5": 1.3308906876687607,
    "mistral-8b_SparseV5-5": 1.1378043391896755,
    "mistral-8b_HybridV5-5": 1.2271687079764588,
    "mistral-8b_RerankV5-5": 1.6339510184048223,
    "mistral-8b_DenseV5-10": 1.6176500193598446,
    "mistral-8b_SparseV5-10": 1.0955122873769287,
    "mistral-8b_HybridV5-10": 1.6522096200667022,
    "mistral-8b_RerankV5-10": 1.6472020700293197,
    "mistral-8b_open_book": 1.6531369925984802,
    "gemma2_9b": -0.699217830531794,
    "gemma2_9b_DenseV3": 0.2772982133162232,
    "gemma2_9b_SparseV3": 0.24254275968653805,
    "gemma2_9b_HybridV3": 0.2993209900957987,
    "gemma2_9b_RerankV3": 0.38155818406030595,
    "gemma2_9b_DenseV5-5": -0.1189709045545948,
    "gemma2_9b_SparseV5-5": -0.31205725303368004,
    "gemma2_9b_HybridV5-5": -0.22269288424689676,
    "gemma2_9b_RerankV5-5": 0.18408942618146673,
    "gemma2_9b_DenseV5-10": 0.167788427136489,
    "gemma2_9b_SparseV5-10": -0.35434930484642685,
    "gemma2_9b_HybridV5-10": 0.2023480278433467,
    "gemma2_9b_RerankV5-10": 0.1973404778059642,
    "gemma2_9b_open_book": 0.20327540037512482
  },
  "component_abilities": {
    "llms": {
      "mistral-8b": 0.7506437616915616,
      "gemma2_9b": -0.699217830531794,
      "llama3-8b": 0.3742519827255838
    },
    "retrievers": {
      "SparseV5-10": 0.34486852568536713,
      "DenseV3": 0.9765160438480172,
      "HybridV3": 0.9985388206275927,
      "SparseV3": 0.941760590218332,
      "DenseV5-5": 0.5802469259771992,
      "SparseV5-5": 0.38716057749811394,
      "RerankV5-5": 0.8833072567132607,
      "HybridV5-10": 0.9015658583751407,
      "RerankV5-10": 0.8965583083377582,
      "RerankV3": 1.0807760145921,
      "DenseV4": 0.8296339017735601,
      "DenseV5-10": 0.867006257668283,
      "open_book": 0.9024932309069188,
      "HybridV5-5": 0.4765249462848972
    }
  }
}