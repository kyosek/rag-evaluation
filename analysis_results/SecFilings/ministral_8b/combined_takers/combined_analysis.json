{
  "overall_stats": {
    "avg_difficulty": 0.621060477083003,
    "avg_discrimination": 0.7072686258408004,
    "total_questions": 340
  },
  "hop_analysis": {
    "1": {
      "avg_difficulty": 0.5096271737158685,
      "avg_discrimination": 0.8250973475831767,
      "num_questions": 150
    },
    "2": {
      "avg_difficulty": 0.7121100441776878,
      "avg_discrimination": 0.7029724296998453,
      "num_questions": 72
    },
    "3": {
      "avg_difficulty": 0.7662762354609951,
      "avg_discrimination": 0.6562476148867052,
      "num_questions": 42
    },
    "4": {
      "avg_difficulty": 0.7662225716182813,
      "avg_discrimination": 0.513597843199107,
      "num_questions": 39
    },
    "5": {
      "avg_difficulty": 0.5777913726370939,
      "avg_discrimination": 0.5,
      "num_questions": 37
    }
  },
  "model_abilities": {
    "llama3-8b_DenseV3": -0.17445802805522115,
    "llama3-8b_SparseV3": -0.20916874502142868,
    "llama3-8b_HybridV3": -0.11216820863940685,
    "llama3-8b_RerankV3": -0.1408992049461001,
    "llama3-8b_DenseV5-5": -0.3771048418549675,
    "llama3-8b_SparseV5-5": -0.45988511232573925,
    "llama3-8b_HybridV5-5": -0.3979916942542878,
    "llama3-8b_RerankV5-5": -0.3389833892315739,
    "llama3-8b_DenseV5-10": -0.29465740924238737,
    "llama3-8b_SparseV5-10": -0.5999706326755863,
    "llama3-8b_HybridV5-10": -0.305080263248126,
    "llama3-8b_RerankV5-10": -0.2662295281137578,
    "llama3-8b_open_book": -0.040090358679899796,
    "mistral-8b_DenseV3": -0.05966724955267372,
    "mistral-8b_SparseV3": -0.09437796651888125,
    "mistral-8b_HybridV3": 0.002622569863140578,
    "mistral-8b_RerankV3": -0.026108426443552657,
    "mistral-8b_DenseV5-5": -0.2623140633524201,
    "mistral-8b_SparseV5-5": -0.3450943338231918,
    "mistral-8b_HybridV5-5": -0.2832009157517404,
    "mistral-8b_RerankV5-5": -0.22419261072902646,
    "mistral-8b_DenseV5-10": -0.17986663073983994,
    "mistral-8b_SparseV5-10": -0.4851798541730388,
    "mistral-8b_HybridV5-10": -0.19028948474557855,
    "mistral-8b_RerankV5-10": -0.15143874961121034,
    "mistral-8b_open_book": 0.07470041982264763,
    "gemma2_9b": 0.13751574061472252,
    "gemma2_9b_DenseV3": -0.412257402273458,
    "gemma2_9b_SparseV3": -0.4469681192396655,
    "gemma2_9b_HybridV3": -0.3499675828576436,
    "gemma2_9b_RerankV3": -0.3786985791643369,
    "gemma2_9b_DenseV5-5": -0.6149042160732043,
    "gemma2_9b_SparseV5-5": -0.6976844865439761,
    "gemma2_9b_HybridV5-5": -0.6357910684725246,
    "gemma2_9b_RerankV5-5": -0.5767827634498107,
    "gemma2_9b_DenseV5-10": -0.5324567834606242,
    "gemma2_9b_SparseV5-10": -0.8377700068938231,
    "gemma2_9b_HybridV5-10": -0.5428796374663628,
    "gemma2_9b_RerankV5-10": -0.5040289023319946,
    "gemma2_9b_open_book": -0.27788973289813657
  },
  "component_abilities": {
    "llms": {
      "mistral-8b": 0.49010589333550675,
      "llama3-8b": 0.3753151148329593,
      "gemma2_9b": 0.13751574061472252
    },
    "retrievers": {
      "open_book": -0.4154054735128591,
      "DenseV3": -0.5497731428881805,
      "HybridV3": -0.48748332347236617,
      "DenseV5-5": -0.7524199566879268,
      "SparseV5-5": -0.8352002271586986,
      "HybridV5-10": -0.6803953780810853,
      "RerankV5-5": -0.7142985040645332,
      "SparseV5-10": -0.9752857475085456,
      "DenseV5-10": -0.6699725240753467,
      "HybridV5-5": -0.7733068090872471,
      "SparseV3": -0.584483859854388,
      "RerankV5-10": -0.6415446429467171,
      "RerankV3": -0.5162143197790594
    }
  }
}