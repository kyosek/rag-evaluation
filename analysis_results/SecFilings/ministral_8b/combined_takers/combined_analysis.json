{
  "overall_stats": {
    "avg_difficulty": 0.5584076912601929,
    "avg_discrimination": 1.315849340852451,
    "total_questions": 340
  },
  "hop_analysis": {
    "1": {
      "avg_difficulty": 0.5085752497022736,
      "avg_discrimination": 1.327877891525538,
      "avg_feasibility": 0.24855546324172945,
      "num_questions": 150
    },
    "2": {
      "avg_difficulty": 0.6023950419690718,
      "avg_discrimination": 1.3240512011750598,
      "avg_feasibility": 0.24385687511864684,
      "num_questions": 72
    },
    "3": {
      "avg_difficulty": 0.6891889488081946,
      "avg_discrimination": 1.3569611662447845,
      "avg_feasibility": 0.2515124762792491,
      "num_questions": 42
    },
    "4": {
      "avg_difficulty": 0.604460258041128,
      "avg_discrimination": 1.1749065576557305,
      "avg_feasibility": 0.2518149991729172,
      "num_questions": 39
    },
    "5": {
      "avg_difficulty": 0.4778378010217094,
      "avg_discrimination": 1.35301840393362,
      "avg_feasibility": 0.25801819845487045,
      "num_questions": 37
    }
  },
  "model_abilities": {
    "llama3-8b_DenseV3": 1.615732760960047,
    "llama3-8b_DenseV4": 1.6680790072716984,
    "llama3-8b_SparseV3": 1.6259411459448327,
    "llama3-8b_HybridV3": 1.6155707449209973,
    "llama3-8b_RerankV3": 1.5894065116659988,
    "llama3-8b_DenseV5-5": 1.5104047264433422,
    "llama3-8b_SparseV5-5": 1.5907843396623695,
    "llama3-8b_HybridV5-5": 1.6751841131682705,
    "llama3-8b_RerankV5-5": 1.6466091269323262,
    "llama3-8b_DenseV5-10": 1.6400604491595012,
    "llama3-8b_SparseV5-10": 1.6651092093802529,
    "llama3-8b_HybridV5-10": 1.5067918903077406,
    "llama3-8b_RerankV5-10": 1.6176053898721041,
    "llama3-8b_open_book": 1.5975804809189915,
    "mistral-8b_DenseV3": 1.6204217902942673,
    "mistral-8b_SparseV3": 1.630630175279053,
    "mistral-8b_HybridV3": 1.6202597742552176,
    "mistral-8b_RerankV3": 1.594095541000219,
    "mistral-8b_DenseV5-5": 1.5150937557775626,
    "mistral-8b_SparseV5-5": 1.5954733689965899,
    "mistral-8b_HybridV5-5": 1.6798731425024909,
    "mistral-8b_RerankV5-5": 1.6512981562665465,
    "mistral-8b_DenseV5-10": 1.6447494784937216,
    "mistral-8b_SparseV5-10": 1.6697982387144732,
    "mistral-8b_HybridV5-10": 1.511480919641961,
    "mistral-8b_RerankV5-10": 1.6222944192063244,
    "mistral-8b_open_book": 1.6022695102532118,
    "gemma2_9b": 0.8169937680596352,
    "gemma2_9b_DenseV3": 1.616924135487468,
    "gemma2_9b_SparseV3": 1.6271325204722538,
    "gemma2_9b_HybridV3": 1.6167621194484179,
    "gemma2_9b_RerankV3": 1.5905978861934196,
    "gemma2_9b_DenseV5-5": 1.5115961009707632,
    "gemma2_9b_SparseV5-5": 1.5919757141897901,
    "gemma2_9b_HybridV5-5": 1.6763754876956911,
    "gemma2_9b_RerankV5-5": 1.6478005014597472,
    "gemma2_9b_DenseV5-10": 1.6412518236869222,
    "gemma2_9b_SparseV5-10": 1.6663005839076737,
    "gemma2_9b_HybridV5-10": 1.5079832648351617,
    "gemma2_9b_RerankV5-10": 1.6187967643995251,
    "gemma2_9b_open_book": 1.598771855446412
  },
  "component_abilities": {
    "llms": {
      "gemma2_9b": 0.8169937680596352,
      "llama3-8b": 0.8158023935322144,
      "mistral-8b": 0.8204914228664347
    },
    "retrievers": {
      "RerankV5-5": 0.8308067334001119,
      "DenseV5-5": 0.6946023329111279,
      "open_book": 0.781778087386777,
      "HybridV5-10": 0.6909894967755263,
      "RerankV5-10": 0.8018029963398898,
      "HybridV3": 0.7997683513887828,
      "DenseV4": 0.852276613739484,
      "HybridV5-5": 0.859381719636056,
      "SparseV3": 0.8101387524126185,
      "SparseV5-5": 0.774981946130155,
      "DenseV5-10": 0.8242580556272869,
      "RerankV3": 0.7736041181337844,
      "DenseV3": 0.7999303674278326,
      "SparseV5-10": 0.8493068158480385
    }
  }
}