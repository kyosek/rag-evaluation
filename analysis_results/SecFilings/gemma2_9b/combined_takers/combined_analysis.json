{
  "overall_stats": {
    "avg_difficulty": 0.5022897034597483,
    "avg_discrimination": 1.0242071399403574,
    "total_questions": 375
  },
  "hop_analysis": {
    "1": {
      "avg_difficulty": 0.5202109184150349,
      "avg_discrimination": 1.00443874496756,
      "avg_feasibility": 0.27032239864965607,
      "num_questions": 150
    },
    "2": {
      "avg_difficulty": 0.46725536811449514,
      "avg_discrimination": 1.056836254691074,
      "avg_feasibility": 0.2529338947909888,
      "num_questions": 146
    },
    "3": {
      "avg_difficulty": 0.5642324491098171,
      "avg_discrimination": 0.9757343525631444,
      "avg_feasibility": 0.25604045537883285,
      "num_questions": 40
    },
    "4": {
      "avg_difficulty": 0.5060576110196222,
      "avg_discrimination": 1.0160942239090633,
      "avg_feasibility": 0.2594655135540581,
      "num_questions": 25
    },
    "5": {
      "avg_difficulty": 0.49192707503934774,
      "avg_discrimination": 1.0487173462393446,
      "avg_feasibility": 0.24859877994687032,
      "num_questions": 14
    }
  },
  "model_abilities": {
    "llama3-8b_DenseV3": 1.6887568746944572,
    "llama3-8b_DenseV4": 1.757652441782274,
    "llama3-8b_SparseV3": 1.752989274579297,
    "llama3-8b_HybridV3": 1.654274428304552,
    "llama3-8b_RerankV3": 1.6841272397277591,
    "llama3-8b_DenseV5-5": 1.583694514232877,
    "llama3-8b_SparseV5-5": 1.6916522938159027,
    "llama3-8b_HybridV5-5": 1.6803201733435733,
    "llama3-8b_RerankV5-5": 1.6763722566045174,
    "llama3-8b_DenseV5-10": 1.6904284539344632,
    "llama3-8b_SparseV5-10": 1.7745068122658774,
    "llama3-8b_HybridV5-10": 1.6438566945144104,
    "llama3-8b_RerankV5-10": 1.6754133908905666,
    "mistral-8b_DenseV3": 1.595267512465679,
    "mistral-8b_SparseV3": 1.6594999123505187,
    "mistral-8b_HybridV3": 1.5607850660757738,
    "mistral-8b_RerankV3": 1.5906378774989811,
    "mistral-8b_DenseV5-5": 1.490205152004099,
    "mistral-8b_SparseV5-5": 1.5981629315871246,
    "mistral-8b_HybridV5-5": 1.5868308111147953,
    "mistral-8b_RerankV5-5": 1.5828828943757394,
    "mistral-8b_DenseV5-10": 1.596939091705685,
    "mistral-8b_SparseV5-10": 1.6810174500370991,
    "mistral-8b_HybridV5-10": 1.5503673322856324,
    "mistral-8b_RerankV5-10": 1.5819240286617884,
    "gemma2_9b_DenseV3": 1.5866820561142183,
    "gemma2_9b_SparseV3": 1.6509144559990578,
    "gemma2_9b_HybridV3": 1.5521996097243131,
    "gemma2_9b_RerankV3": 1.5820524211475204,
    "gemma2_9b_DenseV5-5": 1.4816196956526384,
    "gemma2_9b_SparseV5-5": 1.5895774752356637,
    "gemma2_9b_HybridV5-5": 1.5782453547633344,
    "gemma2_9b_RerankV5-5": 1.5742974380242785,
    "gemma2_9b_DenseV5-10": 1.588353635354224,
    "gemma2_9b_SparseV5-10": 1.6724319936856382,
    "gemma2_9b_HybridV5-10": 1.5417818759341715,
    "gemma2_9b_RerankV5-10": 1.5733385723103277
  },
  "component_abilities": {
    "llms": {
      "gemma2_9b": 0.7864922435331453,
      "llama3-8b": 0.8885670621133842,
      "mistral-8b": 0.7950776998846061
    },
    "retrievers": {
      "RerankV5-5": 0.7878051944911332,
      "DenseV5-5": 0.695127452119493,
      "HybridV5-10": 0.7552896324010262,
      "RerankV5-10": 0.7868463287771824,
      "HybridV3": 0.7657073661911679,
      "DenseV4": 0.8690853796688899,
      "HybridV5-5": 0.7917531112301891,
      "SparseV3": 0.8644222124659127,
      "SparseV5-5": 0.8030852317025184,
      "DenseV5-10": 0.8018613918210789,
      "RerankV3": 0.795560177614375,
      "DenseV3": 0.800189812581073,
      "SparseV5-10": 0.885939750152493
    }
  }
}