{
  "overall_stats": {
    "avg_difficulty": 0.5258377066807554,
    "avg_discrimination": 1.2837477788164533,
    "total_questions": 295
  },
  "hop_analysis": {
    "1": {
      "avg_difficulty": 0.5291477534656913,
      "avg_discrimination": 1.2748060627858873,
      "avg_feasibility": 0.2431294204636626,
      "num_questions": 150
    },
    "2": {
      "avg_difficulty": 0.4226191581012464,
      "avg_discrimination": 1.2493165424820003,
      "avg_feasibility": 0.24690622250420102,
      "num_questions": 46
    },
    "3": {
      "avg_difficulty": 0.5447185248494223,
      "avg_discrimination": 1.29110379961836,
      "avg_feasibility": 0.2563729430499727,
      "num_questions": 35
    },
    "4": {
      "avg_difficulty": 0.5766101305653774,
      "avg_discrimination": 1.3087524284045007,
      "avg_feasibility": 0.2684028804917597,
      "num_questions": 34
    },
    "5": {
      "avg_difficulty": 0.5879862123119727,
      "avg_discrimination": 1.344330294213432,
      "avg_feasibility": 0.23083862527082477,
      "num_questions": 30
    }
  },
  "model_abilities": {
    "llama3-8b_DenseV3": 1.6817319541983227,
    "llama3-8b_DenseV4": 1.6466600523912,
    "llama3-8b_SparseV3": 1.628446503648254,
    "llama3-8b_HybridV3": 1.6641764250813682,
    "llama3-8b_RerankV3": 1.5854652654360164,
    "llama3-8b_DenseV5-5": 1.5770477258018036,
    "llama3-8b_SparseV5-5": 1.6191314709585454,
    "llama3-8b_HybridV5-5": 1.7147143494594927,
    "llama3-8b_RerankV5-5": 1.5371623767243396,
    "llama3-8b_DenseV5-10": 1.6861911458583454,
    "llama3-8b_SparseV5-10": 1.6673750281186357,
    "llama3-8b_HybridV5-10": 1.6343609245575617,
    "llama3-8b_RerankV5-10": 1.6418279375695861,
    "llama3-8b_open_book": 1.6205955327925219,
    "mistral-8b_DenseV3": 1.5979176133540247,
    "mistral-8b_DenseV4": 1.562845711546902,
    "mistral-8b_SparseV3": 1.544632162803956,
    "mistral-8b_HybridV3": 1.5803620842370703,
    "mistral-8b_RerankV3": 1.5016509245917185,
    "mistral-8b_DenseV5-5": 1.493233384957506,
    "mistral-8b_SparseV5-5": 1.5353171301142474,
    "mistral-8b_HybridV5-5": 1.6309000086151948,
    "mistral-8b_RerankV5-5": 1.4533480358800417,
    "mistral-8b_DenseV5-10": 1.6023768050140477,
    "mistral-8b_SparseV5-10": 1.5835606872743377,
    "mistral-8b_HybridV5-10": 1.5505465837132637,
    "mistral-8b_RerankV5-10": 1.5580135967252882,
    "mistral-8b_open_book": 1.536781191948224,
    "gemma2_9b": 0.8144458333584353,
    "gemma2_9b_DenseV3": 1.6339304186244354,
    "gemma2_9b_SparseV3": 1.5806449680743668,
    "gemma2_9b_HybridV3": 1.6163748895074812,
    "gemma2_9b_RerankV3": 1.5376637298621294,
    "gemma2_9b_DenseV5-5": 1.5292461902279166,
    "gemma2_9b_SparseV5-5": 1.5713299353846581,
    "gemma2_9b_HybridV5-5": 1.6669128138856057,
    "gemma2_9b_RerankV5-5": 1.4893608411504526,
    "gemma2_9b_DenseV5-10": 1.6383896102844586,
    "gemma2_9b_SparseV5-10": 1.6195734925447487,
    "gemma2_9b_HybridV5-10": 1.5865593889836747,
    "gemma2_9b_RerankV5-10": 1.5940264019956991,
    "gemma2_9b_open_book": 1.5727939972186347
  },
  "component_abilities": {
    "llms": {
      "gemma2_9b": 0.8144458333584353,
      "llama3-8b": 0.8622473689323223,
      "mistral-8b": 0.7784330280880245
    },
    "retrievers": {
      "RerankV5-5": 0.6749150077920173,
      "DenseV5-5": 0.7148003568694813,
      "open_book": 0.7583481638601994,
      "HybridV5-10": 0.7721135556252393,
      "RerankV5-10": 0.7795805686372638,
      "HybridV3": 0.8019290561490459,
      "DenseV4": 0.7844126834588777,
      "HybridV5-5": 0.8524669805271704,
      "SparseV3": 0.7661991347159316,
      "SparseV5-5": 0.7568841020262229,
      "DenseV5-10": 0.8239437769260232,
      "RerankV3": 0.7232178965036941,
      "DenseV3": 0.8194845852660002,
      "SparseV5-10": 0.8051276591863133
    }
  }
}