{
  "overall_stats": {
    "avg_difficulty": 0.4702526382697479,
    "avg_discrimination": 1.0494342610591363,
    "avg_feasibility": 0.25491506405747805,
    "total_questions": 408
  },
  "hop_analysis": {
    "1": {
      "avg_difficulty": 0.4265062838601556,
      "avg_discrimination": 1.081866686837729,
      "avg_feasibility": 0.2747151997758199,
      "num_questions": 150
    },
    "2": {
      "avg_difficulty": 0.4972347462175684,
      "avg_discrimination": 1.0245643034662772,
      "avg_feasibility": 0.252957210566155,
      "num_questions": 162
    },
    "3": {
      "avg_difficulty": 0.5098540639190369,
      "avg_discrimination": 1.026971575772116,
      "avg_feasibility": 0.24626633055228953,
      "num_questions": 57
    },
    "4": {
      "avg_difficulty": 0.42662028111262695,
      "avg_discrimination": 1.1148913538888687,
      "avg_feasibility": 0.23190645189444561,
      "num_questions": 22
    },
    "5": {
      "avg_difficulty": 0.5228104188191068,
      "avg_discrimination": 0.9908687482568,
      "avg_feasibility": 0.25491506405747805,
      "num_questions": 17
    }
  },
  "model_abilities": {
    "llama3-8b_DenseV3": 1.5592804273308445,
    "llama3-8b_DenseV4": 1.4957487336398576,
    "llama3-8b_SparseV3": 1.5834820020416958,
    "llama3-8b_HybridV3": 1.5274775191782672,
    "llama3-8b_RerankV3": 1.4988167286212217,
    "llama3-8b_DenseV5-5": 1.5261227856230868,
    "llama3-8b_SparseV5-5": 1.5153288587118756,
    "llama3-8b_HybridV5-5": 1.5562844173010764,
    "llama3-8b_RerankV5-5": 1.5829321687655797,
    "llama3-8b_DenseV5-10": 1.5713056436742372,
    "llama3-8b_SparseV5-10": 1.5858646859680365,
    "llama3-8b_HybridV5-10": 1.583264538163513,
    "llama3-8b_RerankV5-10": 1.6325491562408958,
    "mistral-8b_DenseV3": 1.6407609887997905,
    "mistral-8b_SparseV3": 1.6649625635106418,
    "mistral-8b_HybridV3": 1.6089580806472132,
    "mistral-8b_RerankV3": 1.5802972900901677,
    "mistral-8b_DenseV5-5": 1.6076033470920328,
    "mistral-8b_SparseV5-5": 1.5968094201808216,
    "mistral-8b_HybridV5-5": 1.6377649787700224,
    "mistral-8b_RerankV5-5": 1.6644127302345257,
    "mistral-8b_DenseV5-10": 1.6527862051431832,
    "mistral-8b_SparseV5-10": 1.6673452474369825,
    "mistral-8b_HybridV5-10": 1.664745099632459,
    "mistral-8b_RerankV5-10": 1.7140297177098418,
    "gemma2_9b_DenseV3": 1.6305228248057069,
    "gemma2_9b_SparseV3": 1.654724399516558,
    "gemma2_9b_HybridV3": 1.5987199166531294,
    "gemma2_9b_RerankV3": 1.570059126096084,
    "gemma2_9b_DenseV5-5": 1.5973651830979492,
    "gemma2_9b_SparseV5-5": 1.5865712561867378,
    "gemma2_9b_HybridV5-5": 1.6275268147759387,
    "gemma2_9b_RerankV5-5": 1.654174566240442,
    "gemma2_9b_DenseV5-10": 1.6425480411490994,
    "gemma2_9b_SparseV5-10": 1.6571070834428987,
    "gemma2_9b_HybridV5-10": 1.6545069356383753,
    "gemma2_9b_RerankV5-10": 1.703791553715758
  },
  "component_abilities": {
    "llms": {
      "llama3-8b": 0.7549551502347713,
      "gemma2_9b": 0.8261975477096336,
      "mistral-8b": 0.8364357117037173
    },
    "retrievers": {
      "DenseV5-5": 0.7711676353883155,
      "RerankV5-5": 0.8279770185308084,
      "HybridV5-10": 0.8283093879287416,
      "HybridV3": 0.7725223689434959,
      "RerankV3": 0.7438615783864503,
      "DenseV4": 0.7407935834050864,
      "DenseV3": 0.8043252770960732,
      "DenseV5-10": 0.8163504934394658,
      "SparseV5-5": 0.7603737084771043,
      "HybridV5-5": 0.801329267066305,
      "SparseV3": 0.8285268518069243,
      "SparseV5-10": 0.8309095357332651,
      "RerankV5-10": 0.8775940060061245
    }
  }
}