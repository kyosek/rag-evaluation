{
  "overall_stats": {
    "avg_difficulty": 0.28387609893108645,
    "avg_discrimination": 0.9695922579587819,
    "avg_guessing": 0.2475203295735511,
    "avg_feasibility": 0.6861292870400567,
    "total_questions": 403
  },
  "hop_analysis": {
    "1": {
      "avg_difficulty": 0.25212245491264496,
      "avg_discrimination": 0.9729583086753725,
      "avg_guessing": 0.29235993873393584,
      "avg_feasibility": 0.7121789262059546,
      "num_questions": 150
    },
    "2": {
      "avg_difficulty": 0.28829986912270794,
      "avg_discrimination": 0.963497743547503,
      "avg_guessing": 0.2613468776019116,
      "avg_feasibility": 0.6872567211078764,
      "num_questions": 87
    },
    "3": {
      "avg_difficulty": 0.25693833341049954,
      "avg_discrimination": 0.9726407080541164,
      "avg_guessing": 0.2892725240811037,
      "avg_feasibility": 0.715784049336239,
      "num_questions": 38
    },
    "4": {
      "avg_difficulty": 0.3177614056955012,
      "avg_discrimination": 0.9606248230754482,
      "avg_guessing": 0.2523530583253161,
      "avg_feasibility": 0.693060565584905,
      "num_questions": 51
    },
    "5": {
      "avg_difficulty": 0.3315860085530644,
      "avg_discrimination": 0.974356066033067,
      "avg_guessing": 0.2475203295735511,
      "avg_feasibility": 0.6861292870400567,
      "num_questions": 77
    }
  },
  "model_abilities": {
    "llama3-8b_DenseV3": 1.668843035479043,
    "llama3-8b_DenseV4": 1.8284121167349605,
    "llama3-8b_SparseV3": 1.6736653652547926,
    "llama3-8b_HybridV3": 1.6004998046368903,
    "llama3-8b_RerankV3": 1.6472825566745204,
    "llama3-8b_DenseV5-5": 1.647758101032835,
    "llama3-8b_SparseV5-5": 1.6876404639208453,
    "llama3-8b_HybridV5-5": 1.6972638494566148,
    "llama3-8b_RerankV5-5": 1.635914778108166,
    "llama3-8b_DenseV5-10": 1.729169355031145,
    "llama3-8b_SparseV5-10": 1.6058750407010263,
    "llama3-8b_HybridV5-10": 1.7412264153419448,
    "llama3-8b_RerankV5-10": 1.722521554468029,
    "llama3-8b_open_book": 1.8564719683184299,
    "mistral-8b_DenseV3": 2.004362309048499,
    "mistral-8b_SparseV3": 2.009184638824249,
    "mistral-8b_HybridV3": 1.9360190782063464,
    "mistral-8b_RerankV3": 1.9828018302439765,
    "mistral-8b_DenseV5-5": 1.9832773746022911,
    "mistral-8b_SparseV5-5": 2.0231597374903014,
    "mistral-8b_HybridV5-5": 2.032783123026071,
    "mistral-8b_RerankV5-5": 1.971434051677622,
    "mistral-8b_DenseV5-10": 2.064688628600601,
    "mistral-8b_SparseV5-10": 1.9413943142704824,
    "mistral-8b_HybridV5-10": 2.0767456889114007,
    "mistral-8b_RerankV5-10": 2.058040828037485,
    "mistral-8b_open_book": 2.191991241887886,
    "gemma2_9b": 0.24154330491821774,
    "gemma2_9b_DenseV3": 1.726936755130748,
    "gemma2_9b_SparseV3": 1.7317590849064977,
    "gemma2_9b_HybridV3": 1.6585935242885954,
    "gemma2_9b_RerankV3": 1.7053762763262252,
    "gemma2_9b_DenseV5-5": 1.7058518206845399,
    "gemma2_9b_SparseV5-5": 1.7457341835725502,
    "gemma2_9b_HybridV5-5": 1.7553575691083196,
    "gemma2_9b_RerankV5-5": 1.6940084977598708,
    "gemma2_9b_DenseV5-10": 1.78726307468285,
    "gemma2_9b_SparseV5-10": 1.6639687603527311,
    "gemma2_9b_HybridV5-10": 1.7993201349936498,
    "gemma2_9b_RerankV5-10": 1.780615274119734,
    "gemma2_9b_open_book": 1.9145656879701347
  },
  "component_abilities": {
    "llms": {
      "mistral-8b": 0.5189688588359689,
      "gemma2_9b": 0.24154330491821774,
      "llama3-8b": 0.18344958526651275
    },
    "retrievers": {
      "SparseV5-10": 1.4224254554345135,
      "DenseV3": 1.48539345021253,
      "HybridV3": 1.4170502193703776,
      "SparseV3": 1.4902157799882798,
      "DenseV5-5": 1.4643085157663223,
      "SparseV5-5": 1.5041908786543325,
      "RerankV5-5": 1.4524651928416532,
      "HybridV5-10": 1.557776830075432,
      "RerankV5-10": 1.5390719692015162,
      "RerankV3": 1.4638329714080076,
      "DenseV4": 1.6449625314684477,
      "DenseV5-10": 1.5457197697646323,
      "open_book": 1.673022383051917,
      "HybridV5-5": 1.513814264190102
    }
  }
}