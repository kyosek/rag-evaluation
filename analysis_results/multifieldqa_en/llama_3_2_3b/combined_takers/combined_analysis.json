{
  "overall_stats": {
    "avg_difficulty": 0.5062012809879037,
    "avg_discrimination": 1.319184960995486,
    "total_questions": 329
  },
  "hop_analysis": {
    "1": {
      "avg_difficulty": 0.48661855342816807,
      "avg_discrimination": 1.3297035025651434,
      "avg_feasibility": 0.26519363631856646,
      "num_questions": 150
    },
    "2": {
      "avg_difficulty": 0.48638039352581397,
      "avg_discrimination": 1.3706090171236187,
      "avg_feasibility": 0.25146383180789145,
      "num_questions": 43
    },
    "3": {
      "avg_difficulty": 0.48968504166193644,
      "avg_discrimination": 1.321030775644405,
      "avg_feasibility": 0.2329675102044375,
      "num_questions": 41
    },
    "4": {
      "avg_difficulty": 0.5223548673348459,
      "avg_discrimination": 1.2058338037823588,
      "avg_feasibility": 0.2457597291139666,
      "num_questions": 32
    },
    "5": {
      "avg_difficulty": 0.5688990324814391,
      "avg_discrimination": 1.3154158019678048,
      "avg_feasibility": 0.2521268610789522,
      "num_questions": 63
    }
  },
  "model_abilities": {
    "llama3-8b_DenseV3": 1.564145358734685,
    "llama3-8b_DenseV4": 1.62321015561569,
    "llama3-8b_SparseV3": 1.5914072214220552,
    "llama3-8b_HybridV3": 1.6025050201777948,
    "llama3-8b_RerankV3": 1.5484046652077947,
    "llama3-8b_DenseV5-5": 1.6588327375601892,
    "llama3-8b_SparseV5-5": 1.6260566686202869,
    "llama3-8b_HybridV5-5": 1.5909279094914508,
    "llama3-8b_RerankV5-5": 1.628396792497464,
    "llama3-8b_DenseV5-10": 1.5819048797251811,
    "llama3-8b_SparseV5-10": 1.6165645309131649,
    "llama3-8b_HybridV5-10": 1.650609405601773,
    "llama3-8b_RerankV5-10": 1.5793823029449685,
    "llama3-8b_open_book": 1.6745875147564957,
    "mistral-8b_DenseV3": 1.555136838771975,
    "mistral-8b_DenseV4": 1.61420163565298,
    "mistral-8b_SparseV3": 1.5823987014593452,
    "mistral-8b_HybridV3": 1.593496500215085,
    "mistral-8b_RerankV3": 1.5393961452450848,
    "mistral-8b_DenseV5-5": 1.6498242175974793,
    "mistral-8b_SparseV5-5": 1.617048148657577,
    "mistral-8b_HybridV5-5": 1.581919389528741,
    "mistral-8b_RerankV5-5": 1.6193882725347541,
    "mistral-8b_DenseV5-10": 1.5728963597624712,
    "mistral-8b_SparseV5-10": 1.607556010950455,
    "mistral-8b_HybridV5-10": 1.6416008856390631,
    "mistral-8b_RerankV5-10": 1.5703737829822586,
    "mistral-8b_open_book": 1.6655789947937858,
    "gemma2_9b": 0.8165520077498098,
    "gemma2_9b_DenseV3": 1.595828354458017,
    "gemma2_9b_SparseV3": 1.6230902171453871,
    "gemma2_9b_HybridV3": 1.634188015901127,
    "gemma2_9b_RerankV3": 1.580087660931127,
    "gemma2_9b_DenseV5-5": 1.6905157332835214,
    "gemma2_9b_SparseV5-5": 1.657739664343619,
    "gemma2_9b_HybridV5-5": 1.622610905214783,
    "gemma2_9b_RerankV5-5": 1.6600797882207963,
    "gemma2_9b_DenseV5-10": 1.6135878754485131,
    "gemma2_9b_SparseV5-10": 1.648247526636497,
    "gemma2_9b_HybridV5-10": 1.682292401325105,
    "gemma2_9b_RerankV5-10": 1.6110652986683007,
    "gemma2_9b_open_book": 1.7062705104798277
  },
  "component_abilities": {
    "llms": {
      "gemma2_9b": 0.8165520077498098,
      "llama3-8b": 0.7848690120264777,
      "mistral-8b": 0.7758604920637678
    },
    "retrievers": {
      "RerankV5-5": 0.8435277804709864,
      "DenseV5-5": 0.8739637255337116,
      "open_book": 0.889718502730018,
      "HybridV5-10": 0.8657403935752953,
      "RerankV5-10": 0.7945132909184909,
      "HybridV3": 0.8176360081513172,
      "DenseV4": 0.8383411435892122,
      "HybridV5-5": 0.8060588974649732,
      "SparseV3": 0.8065382093955773,
      "SparseV5-5": 0.8411876565938091,
      "DenseV5-10": 0.7970358676987034,
      "RerankV3": 0.763535653181317,
      "DenseV3": 0.7792763467082071,
      "SparseV5-10": 0.8316955188866871
    }
  }
}