{
  "overall_stats": {
    "avg_difficulty": 0.45766460119207325,
    "avg_discrimination": 1.0099921533655698,
    "avg_guessing": 0.29304242050063756,
    "avg_feasibility": 0.6790082588416801,
    "total_questions": 259
  },
  "hop_analysis": {
    "1": {
      "avg_difficulty": 0.44289961349465545,
      "avg_discrimination": 1.0497274085593506,
      "avg_guessing": 0.26063804545882674,
      "avg_feasibility": 0.7644903536654213,
      "num_questions": 150
    },
    "2": {
      "avg_difficulty": 0.4591931553449361,
      "avg_discrimination": 0.9399455478107076,
      "avg_guessing": 0.258085765330647,
      "avg_feasibility": 0.7081738309462282,
      "num_questions": 63
    },
    "3": {
      "avg_difficulty": 0.47846549364403235,
      "avg_discrimination": 0.8860946507999932,
      "avg_guessing": 0.245825691665094,
      "avg_feasibility": 0.7117463082646918,
      "num_questions": 14
    },
    "4": {
      "avg_difficulty": 0.5285679943055921,
      "avg_discrimination": 1.1363942025687668,
      "avg_guessing": 0.23667663089714633,
      "avg_feasibility": 0.7701832511420217,
      "num_questions": 19
    },
    "5": {
      "avg_difficulty": 0.4945932380765372,
      "avg_discrimination": 0.8396516896691492,
      "avg_guessing": 0.29304242050063756,
      "avg_feasibility": 0.6790082588416801,
      "num_questions": 13
    }
  },
  "model_abilities": {
    "llama3-8b_DenseV3": 0.020639225940767503,
    "llama3-8b_DenseV4": -1.1461960091520507,
    "llama3-8b_SparseV3": -0.055645175806875224,
    "llama3-8b_HybridV3": 0.05166006087305819,
    "llama3-8b_RerankV3": -0.09190853649492992,
    "llama3-8b_DenseV5-5": -0.03822371404505409,
    "llama3-8b_SparseV5-5": 0.1410660903169092,
    "llama3-8b_HybridV5-5": -0.09345089870253709,
    "llama3-8b_RerankV5-5": 0.0799947955176683,
    "llama3-8b_DenseV5-10": 0.0695729370891156,
    "llama3-8b_SparseV5-10": -0.1010465940990597,
    "llama3-8b_HybridV5-10": 0.05161105415413236,
    "llama3-8b_RerankV5-10": 0.1801145915201039,
    "llama3-8b_open_book": 0.4395911689703631,
    "mistral-8b_DenseV3": 1.5107953864020767,
    "mistral-8b_SparseV3": 1.434510984654434,
    "mistral-8b_HybridV3": 1.5418162213343674,
    "mistral-8b_RerankV3": 1.3982476239663792,
    "mistral-8b_DenseV5-5": 1.451932446416255,
    "mistral-8b_SparseV5-5": 1.6312222507782184,
    "mistral-8b_HybridV5-5": 1.396705261758772,
    "mistral-8b_RerankV5-5": 1.5701509559789775,
    "mistral-8b_DenseV5-10": 1.5597290975504248,
    "mistral-8b_SparseV5-10": 1.3891095663622495,
    "mistral-8b_HybridV5-10": 1.5417672146154415,
    "mistral-8b_RerankV5-10": 1.670270751981413,
    "mistral-8b_open_book": 1.9297473294316723,
    "gemma2_9b": 0.31993892356193077,
    "gemma2_9b_DenseV3": 1.877394025695152,
    "gemma2_9b_SparseV3": 1.8011096239475093,
    "gemma2_9b_HybridV3": 1.9084148606274427,
    "gemma2_9b_RerankV3": 1.7648462632594546,
    "gemma2_9b_DenseV5-5": 1.8185310857093304,
    "gemma2_9b_SparseV5-5": 1.9978208900712937,
    "gemma2_9b_HybridV5-5": 1.7633039010518474,
    "gemma2_9b_RerankV5-5": 1.9367495952720528,
    "gemma2_9b_DenseV5-10": 1.9263277368435001,
    "gemma2_9b_SparseV5-10": 1.7557082056553248,
    "gemma2_9b_HybridV5-10": 1.9083658539085169,
    "gemma2_9b_RerankV5-10": 2.0368693912744886,
    "gemma2_9b_open_book": 2.2963459687247476
  },
  "component_abilities": {
    "llms": {
      "mistral-8b": -0.04665971573114457,
      "gemma2_9b": 0.31993892356193077,
      "llama3-8b": -1.5368158761924537
    },
    "retrievers": {
      "SparseV5-10": 1.435769282093394,
      "DenseV3": 1.5574551021332212,
      "HybridV3": 1.588475937065512,
      "SparseV3": 1.4811707003855785,
      "DenseV5-5": 1.4985921621473997,
      "SparseV5-5": 1.677881966509363,
      "RerankV5-5": 1.616810671710122,
      "HybridV5-10": 1.588426930346586,
      "RerankV5-10": 1.7169304677125576,
      "RerankV3": 1.4449073396975238,
      "DenseV4": 0.3906198670404031,
      "DenseV5-10": 1.6063888132815693,
      "open_book": 1.9764070451628168,
      "HybridV5-5": 1.4433649774899167
    }
  }
}