{
  "overall_stats": {
    "avg_difficulty": 0.5319055645097246,
    "avg_discrimination": 1.2931311201984061,
    "total_questions": 259
  },
  "hop_analysis": {
    "1": {
      "avg_difficulty": 0.5044588003959934,
      "avg_discrimination": 1.2984048507619064,
      "avg_feasibility": 0.23071337410786166,
      "num_questions": 150
    },
    "2": {
      "avg_difficulty": 0.5843351397572855,
      "avg_discrimination": 1.2408519985554425,
      "avg_feasibility": 0.24648519891409507,
      "num_questions": 63
    },
    "3": {
      "avg_difficulty": 0.517317609158423,
      "avg_discrimination": 1.3145453364866868,
      "avg_feasibility": 0.2468891003016978,
      "num_questions": 14
    },
    "4": {
      "avg_difficulty": 0.5541256462704913,
      "avg_discrimination": 1.3706343197318651,
      "avg_feasibility": 0.2670202678861671,
      "num_questions": 19
    },
    "5": {
      "avg_difficulty": 0.5777518105041064,
      "avg_discrimination": 1.3492976786453288,
      "avg_feasibility": 0.24050861780967484,
      "num_questions": 13
    }
  },
  "model_abilities": {
    "llama3-8b_DenseV3": 1.6285803871485978,
    "llama3-8b_DenseV4": 1.605229915326431,
    "llama3-8b_SparseV3": 1.5488979365518065,
    "llama3-8b_HybridV3": 1.6154586619112752,
    "llama3-8b_RerankV3": 1.5405035194750636,
    "llama3-8b_DenseV5-5": 1.5990328182283806,
    "llama3-8b_SparseV5-5": 1.5954667025408744,
    "llama3-8b_HybridV5-5": 1.5928735971814436,
    "llama3-8b_RerankV5-5": 1.6004594408303912,
    "llama3-8b_DenseV5-10": 1.5657143835885954,
    "llama3-8b_SparseV5-10": 1.6225825294178828,
    "llama3-8b_HybridV5-10": 1.6477299628468915,
    "llama3-8b_RerankV5-10": 1.6035915683757942,
    "llama3-8b_open_book": 1.6928973547534532,
    "mistral-8b_DenseV3": 1.5604284848856538,
    "mistral-8b_SparseV3": 1.4807460342888625,
    "mistral-8b_HybridV3": 1.5473067596483312,
    "mistral-8b_RerankV3": 1.4723516172121196,
    "mistral-8b_DenseV5-5": 1.5308809159654366,
    "mistral-8b_SparseV5-5": 1.5273148002779304,
    "mistral-8b_HybridV5-5": 1.5247216949184996,
    "mistral-8b_RerankV5-5": 1.532307538567447,
    "mistral-8b_DenseV5-10": 1.4975624813256512,
    "mistral-8b_SparseV5-10": 1.5544306271549386,
    "mistral-8b_HybridV5-10": 1.5795780605839473,
    "mistral-8b_RerankV5-10": 1.5354396661128502,
    "mistral-8b_open_book": 1.624745452490509,
    "gemma2_9b": 0.819849565224942,
    "gemma2_9b_DenseV3": 1.6454106559523187,
    "gemma2_9b_SparseV3": 1.5657282053555277,
    "gemma2_9b_HybridV3": 1.6322889307149961,
    "gemma2_9b_RerankV3": 1.5573337882787848,
    "gemma2_9b_DenseV5-5": 1.6158630870321016,
    "gemma2_9b_SparseV5-5": 1.6122969713445956,
    "gemma2_9b_HybridV5-5": 1.6097038659851646,
    "gemma2_9b_RerankV5-5": 1.6172897096341123,
    "gemma2_9b_DenseV5-10": 1.5825446523923163,
    "gemma2_9b_SparseV5-10": 1.6394127982216038,
    "gemma2_9b_HybridV5-10": 1.6645602316506125,
    "gemma2_9b_RerankV5-10": 1.6204218371795154,
    "gemma2_9b_open_book": 1.7097276235571741
  },
  "component_abilities": {
    "llms": {
      "gemma2_9b": 0.819849565224942,
      "llama3-8b": 0.8030192964212209,
      "mistral-8b": 0.7348673941582768
    },
    "retrievers": {
      "RerankV5-5": 0.7974401444091702,
      "DenseV5-5": 0.7960135218071597,
      "open_book": 0.8898780583322321,
      "HybridV5-10": 0.8447106664256705,
      "RerankV5-10": 0.8005722719545734,
      "HybridV3": 0.8124393654900542,
      "DenseV4": 0.80221061890521,
      "HybridV5-5": 0.7898543007602227,
      "SparseV3": 0.7458786401305857,
      "SparseV5-5": 0.7924474061196536,
      "DenseV5-10": 0.7626950871673743,
      "RerankV3": 0.7374842230538428,
      "DenseV3": 0.8255610907273768,
      "SparseV5-10": 0.8195632329966618
    }
  }
}