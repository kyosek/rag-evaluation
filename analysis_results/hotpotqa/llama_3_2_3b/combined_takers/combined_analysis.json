{
  "overall_stats": {
    "avg_difficulty": 0.5027109580045185,
    "avg_discrimination": 1.36216613761538,
    "total_questions": 243
  },
  "hop_analysis": {
    "1": {
      "avg_difficulty": 0.5098363297632366,
      "avg_discrimination": 1.37302224068086,
      "avg_feasibility": 0.22878526387165066,
      "num_questions": 150
    },
    "2": {
      "avg_difficulty": 0.43602791039191,
      "avg_discrimination": 1.3139288536921125,
      "avg_feasibility": 0.24054583676601915,
      "num_questions": 38
    },
    "3": {
      "avg_difficulty": 0.5448106965015176,
      "avg_discrimination": 1.3568575735463286,
      "avg_feasibility": 0.27076949590391647,
      "num_questions": 19
    },
    "4": {
      "avg_difficulty": 0.45193576587383155,
      "avg_discrimination": 1.3915387596977866,
      "avg_feasibility": 0.232442937451567,
      "num_questions": 18
    },
    "5": {
      "avg_difficulty": 0.5904447620256753,
      "avg_discrimination": 1.3497637403426492,
      "avg_feasibility": 0.22681242706730664,
      "num_questions": 18
    }
  },
  "model_abilities": {
    "llama3-8b_DenseV3": 1.6273424268864956,
    "llama3-8b_DenseV4": 1.5413970861165471,
    "llama3-8b_SparseV3": 1.672477955718711,
    "llama3-8b_HybridV3": 1.6627410999333592,
    "llama3-8b_RerankV3": 1.529398915508854,
    "llama3-8b_DenseV5-5": 1.613007136289713,
    "llama3-8b_SparseV5-5": 1.6817769404992324,
    "llama3-8b_HybridV5-5": 1.5100272580690928,
    "llama3-8b_RerankV5-5": 1.649827626779342,
    "llama3-8b_DenseV5-10": 1.5713595348604688,
    "llama3-8b_SparseV5-10": 1.6689325971536622,
    "llama3-8b_HybridV5-10": 1.630296640081391,
    "llama3-8b_RerankV5-10": 1.661279055290382,
    "llama3-8b_open_book": 1.636297872158867,
    "mistral-8b_DenseV3": 1.6078654575971325,
    "mistral-8b_DenseV4": 1.5219201168271839,
    "mistral-8b_SparseV3": 1.6530009864293478,
    "mistral-8b_HybridV3": 1.643264130643996,
    "mistral-8b_RerankV3": 1.509921946219491,
    "mistral-8b_DenseV5-5": 1.5935301670003499,
    "mistral-8b_SparseV5-5": 1.6622999712098692,
    "mistral-8b_HybridV5-5": 1.4905502887797297,
    "mistral-8b_RerankV5-5": 1.6303506574899789,
    "mistral-8b_DenseV5-10": 1.5518825655711055,
    "mistral-8b_SparseV5-10": 1.649455627864299,
    "mistral-8b_HybridV5-10": 1.610819670792028,
    "mistral-8b_RerankV5-10": 1.6418020860010185,
    "mistral-8b_open_book": 1.6168209028695038,
    "gemma2_9b": 0.7440232062364738,
    "gemma2_9b_DenseV3": 1.5489749472868337,
    "gemma2_9b_SparseV3": 1.5941104761190492,
    "gemma2_9b_HybridV3": 1.5843736203336973,
    "gemma2_9b_RerankV3": 1.4510314359091923,
    "gemma2_9b_DenseV5-5": 1.534639656690051,
    "gemma2_9b_SparseV5-5": 1.6034094608995706,
    "gemma2_9b_HybridV5-5": 1.431659778469431,
    "gemma2_9b_RerankV5-5": 1.57146014717968,
    "gemma2_9b_DenseV5-10": 1.492992055260807,
    "gemma2_9b_SparseV5-10": 1.5905651175540003,
    "gemma2_9b_HybridV5-10": 1.5519291604817291,
    "gemma2_9b_RerankV5-10": 1.5829115756907202,
    "gemma2_9b_open_book": 1.5579303925592052
  },
  "component_abilities": {
    "llms": {
      "gemma2_9b": 0.7440232062364738,
      "llama3-8b": 0.8223906858361356,
      "mistral-8b": 0.8029137165467723
    },
    "retrievers": {
      "RerankV5-5": 0.8274369409432064,
      "DenseV5-5": 0.7906164504535774,
      "open_book": 0.8139071863227314,
      "HybridV5-10": 0.8079059542452555,
      "RerankV5-10": 0.8388883694542463,
      "HybridV3": 0.8403504140972236,
      "DenseV4": 0.7190064002804115,
      "HybridV5-5": 0.6876365722329573,
      "SparseV3": 0.8500872698825754,
      "SparseV5-5": 0.8593862546630968,
      "DenseV5-10": 0.7489688490243331,
      "RerankV3": 0.7070082296727186,
      "DenseV3": 0.80495174105036,
      "SparseV5-10": 0.8465419113175265
    }
  }
}