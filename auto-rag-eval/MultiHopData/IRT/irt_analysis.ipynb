{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Union, Tuple\n",
    "import json\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExamResult:\n",
    "    \"\"\"Class to store exam results for a model configuration\"\"\"\n",
    "    llm_name: str\n",
    "    retriever_name: Optional[str] = None\n",
    "    responses: Optional[List[bool]] = None\n",
    "    num_hops: Optional[List[int]] = None\n",
    "    exam_type: Optional[str] = None\n",
    "    \n",
    "    @classmethod\n",
    "    def combine_exam_takers(cls, results: List['ExamResult']) -> 'ExamResult':\n",
    "        \"\"\"Combine results from different exam takers (LLMs) that took the same exam by concatenating their responses\"\"\"\n",
    "        if not results:\n",
    "            raise ValueError(\"Cannot combine empty list of results\")\n",
    "            \n",
    "        # Verify all results have compatible type\n",
    "        first = results[0]\n",
    "        if not all(r.retriever_name == first.retriever_name for r in results):\n",
    "            raise ValueError(\"All results must have the same retriever type\")\n",
    "            \n",
    "        # Simply concatenate responses and hop numbers\n",
    "        combined_responses = []\n",
    "        combined_hops = []\n",
    "        for result in results:\n",
    "            combined_responses.extend(result.responses)\n",
    "            if result.num_hops:\n",
    "                combined_hops.extend(result.num_hops)\n",
    "            \n",
    "        llm_names = \"_\".join(r.llm_name for r in results)\n",
    "        \n",
    "        return cls(\n",
    "            llm_name=f\"combined_{llm_names}\",\n",
    "            retriever_name=first.retriever_name,\n",
    "            responses=combined_responses,\n",
    "            num_hops=combined_hops,\n",
    "            exam_type=first.exam_type\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json_file(cls, filepath: str, llm_name: str, retriever_name: Optional[str] = None, \n",
    "                      exam_type: Optional[str] = None) -> 'ExamResult':\n",
    "        \"\"\"Create an ExamResult instance from a JSON file containing exam responses\"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                # First try to load as a single JSON object\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    if not isinstance(data, list):\n",
    "                        data = [data]\n",
    "                except json.JSONDecodeError:\n",
    "                    # If that fails, try reading line by line\n",
    "                    f.seek(0)\n",
    "                    data = []\n",
    "                    for line in f:\n",
    "                        line = line.strip()\n",
    "                        if line:  # Skip empty lines\n",
    "                            try:\n",
    "                                data.append(json.loads(line))\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print(f\"Warning: Skipping invalid JSON line in {filepath}\")\n",
    "            \n",
    "            if not data:\n",
    "                raise ValueError(f\"No valid JSON data found in {filepath}\")\n",
    "            \n",
    "            responses = []\n",
    "            num_hops = []\n",
    "            \n",
    "            for item in data:\n",
    "                # Extract response data\n",
    "                if 'is_correct' in item:\n",
    "                    responses.append(item['is_correct'])\n",
    "                else:\n",
    "                    # Try to determine correctness by comparing answers\n",
    "                    is_correct = (\n",
    "                        'model_answer' in item and \n",
    "                        'correct_answer' in item and \n",
    "                        item['model_answer'].strip().upper() == item['correct_answer'].strip().upper()\n",
    "                    )\n",
    "                    responses.append(is_correct)\n",
    "                \n",
    "                # Extract hop data\n",
    "                if 'number_of_hops' in item:\n",
    "                    num_hops.append(item['number_of_hops'])\n",
    "                elif 'num_hops' in item:\n",
    "                    num_hops.append(item['num_hops'])\n",
    "                else:\n",
    "                    num_hops.append(0)  # Default to 0 hops if not specified\n",
    "            \n",
    "            return cls(\n",
    "                llm_name=llm_name,\n",
    "                retriever_name=retriever_name,\n",
    "                responses=responses,\n",
    "                num_hops=num_hops,\n",
    "                exam_type=exam_type\n",
    "            )\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Could not find file: {filepath}\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error processing {filepath}: {str(e)}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def combine_exam_results(cls, result1: 'ExamResult', result2: 'ExamResult') -> 'ExamResult':\n",
    "        \"\"\"Combine two exam results into a single result\"\"\"\n",
    "        if result1.llm_name != result2.llm_name or result1.retriever_name != result2.retriever_name:\n",
    "            raise ValueError(\"Cannot combine results from different models or retrievers\")\n",
    "        \n",
    "        return cls(\n",
    "            llm_name=result1.llm_name,\n",
    "            retriever_name=result1.retriever_name,\n",
    "            responses=result1.responses + result2.responses,\n",
    "            num_hops=result1.num_hops + result2.num_hops,\n",
    "            exam_type=\"combined\"\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json_files(cls, filepaths: Dict[str, Dict[str, Union[str, Dict[str, str]]]],\n",
    "                       combine_exams: bool = False,\n",
    "                       combine_exam_takers: bool = False) -> List['ExamResult']:\n",
    "        \"\"\"Create ExamResult instances from filepaths, with option to combine exam takers\"\"\"\n",
    "        results = []\n",
    "        exam_taker_groups = defaultdict(list)  # Group by retriever and exam type\n",
    "        \n",
    "        for llm_name, retriever_paths in filepaths.items():\n",
    "            for retriever_name, filepath_info in retriever_paths.items():\n",
    "                try:\n",
    "                    ret_name = None if retriever_name == 'closed_book' else retriever_name\n",
    "                    \n",
    "                    if combine_exams and isinstance(filepath_info, dict):\n",
    "                        # Load and combine single/multi hop exam results\n",
    "                        single_result = cls.from_json_file(\n",
    "                            filepath_info['single'], llm_name, ret_name, exam_type=\"single\")\n",
    "                        multi_result = cls.from_json_file(\n",
    "                            filepath_info['multi'], llm_name, ret_name, exam_type=\"multi\")\n",
    "                        combined_result = cls.combine_exam_results(single_result, multi_result)\n",
    "                        \n",
    "                        if combine_exam_takers:\n",
    "                            # Group by retriever type for later combination\n",
    "                            key = (ret_name, combined_result.exam_type)\n",
    "                            exam_taker_groups[key].append(combined_result)\n",
    "                        else:\n",
    "                            results.append(combined_result)\n",
    "                    else:\n",
    "                        # Load single exam result\n",
    "                        filepath = filepath_info if isinstance(filepath_info, str) else filepath_info['default']\n",
    "                        result = cls.from_json_file(filepath, llm_name, ret_name)\n",
    "                        \n",
    "                        if combine_exam_takers:\n",
    "                            key = (ret_name, result.exam_type)\n",
    "                            exam_taker_groups[key].append(result)\n",
    "                        else:\n",
    "                            results.append(result)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Failed to load results for {llm_name}/{retriever_name}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        if combine_exam_takers:\n",
    "            # Combine results from different exam takers for each group\n",
    "            for (ret_name, exam_type), group_results in exam_taker_groups.items():\n",
    "                if len(group_results) > 1:  # Only combine if we have multiple results\n",
    "                    try:\n",
    "                        combined = cls.combine_exam_takers(group_results)\n",
    "                        results.append(combined)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Warning: Failed to combine exam takers for {ret_name}/{exam_type}: {e}\")\n",
    "        \n",
    "        if not results:\n",
    "            raise ValueError(\"No valid exam results could be loaded\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "class MultihopIRTModel:\n",
    "    \"\"\"Hierarchical IRT model for multihop question evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self, exam_results: Union[ExamResult, List[ExamResult]], num_questions: int):\n",
    "        # Convert single ExamResult to list if necessary\n",
    "        if isinstance(exam_results, ExamResult):\n",
    "            exam_results = [exam_results]\n",
    "            \n",
    "        self.exam_results = exam_results\n",
    "        self.num_questions = num_questions\n",
    "        \n",
    "        # Map unique LLMs and retrievers to indices\n",
    "        self.llm_map = {\n",
    "            llm: idx for idx, llm in enumerate(\n",
    "                set(result.llm_name for result in exam_results)\n",
    "            )\n",
    "        }\n",
    "        self.retriever_map = {\n",
    "            ret: idx for idx, ret in enumerate(\n",
    "                set(result.retriever_name for result in exam_results if result.retriever_name)\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Convert responses to numpy array\n",
    "        self.response_matrix = np.array([\n",
    "            result.responses for result in exam_results\n",
    "        ])\n",
    "        \n",
    "        # Store number of hops\n",
    "        self.num_hops = np.array([\n",
    "            result.num_hops for result in exam_results\n",
    "        ])\n",
    "        \n",
    "        # Model dimensions\n",
    "        self.num_llms = len(self.llm_map)\n",
    "        self.num_retrievers = len(self.retriever_map)\n",
    "        self.num_models = len(exam_results)\n",
    "        self.model_colors = {}\n",
    "        \n",
    "        colors = plt.cm.tab20(np.linspace(0, 1, len(exam_results)))\n",
    "        for i, result in enumerate(exam_results):\n",
    "            key = f\"{result.llm_name}_{result.retriever_name}\"\n",
    "            self.model_colors[key] = colors[i]\n",
    "        \n",
    "    def compute_theta(self, theta_params: np.array) -> np.array:\n",
    "        \"\"\"Compute ability parameters for each model\"\"\"\n",
    "        llm_params = theta_params[:self.num_llms]\n",
    "        retriever_params = theta_params[self.num_llms:self.num_llms + self.num_retrievers]\n",
    "        \n",
    "        abilities = []\n",
    "        for result in self.exam_results:\n",
    "            ability = llm_params[self.llm_map[result.llm_name]]\n",
    "            if result.retriever_name:\n",
    "                ability += retriever_params[self.retriever_map[result.retriever_name]]\n",
    "            abilities.append(ability)\n",
    "            \n",
    "        return np.array(abilities)\n",
    "    \n",
    "    def irt_3pl(self, theta: np.array, a: float, b: float) -> float:\n",
    "        \"\"\"3PL IRT model with fixed guessing parameter c=0.25\"\"\"\n",
    "        c = 0.25  # Fixed for 4-choice questions\n",
    "        return c + ((1 - c) / (1 + np.exp(-a * (theta - b))))\n",
    "    \n",
    "    def irt_3pl_with_feasibility(self, theta: np.array, a: float, b: float, c: float, gamma: float) -> float:\n",
    "        \"\"\"\n",
    "        Extended 3PL IRT model with feasibility parameter\n",
    "        \n",
    "        Parameters:\n",
    "        - theta: ability parameter\n",
    "        - a: discrimination parameter\n",
    "        - b: difficulty parameter\n",
    "        - c: guessing parameter (typically 0.25 for 4-choice questions)\n",
    "        - gamma: feasibility parameter (upper bound on probability)\n",
    "        \n",
    "        Returns:\n",
    "        - Probability of correct response\n",
    "        \"\"\"\n",
    "        if not (0 <= c <= gamma <= 1):\n",
    "            raise ValueError(\"Parameters must satisfy: 0 <= c <= gamma <= 1\")\n",
    "        if a <= 0:\n",
    "            raise ValueError(\"Discrimination parameter 'a' must be positive\")\n",
    "            \n",
    "        logit = -a * (theta - b)\n",
    "        # Prevent overflow in exp\n",
    "        logit = np.clip(logit, -100, 100)\n",
    "        return c + (gamma - c) / (1 + np.exp(logit))\n",
    "    \n",
    "    def neg_log_likelihood(self, params: np.array) -> float:\n",
    "        \"\"\"Compute negative log likelihood for optimization\"\"\"\n",
    "        # Unpack parameters\n",
    "        a = params[:self.num_questions]  # discrimination\n",
    "        b = params[self.num_questions:2*self.num_questions]  # difficulty\n",
    "        theta = self.compute_theta(params[2*self.num_questions:])\n",
    "        \n",
    "        # Compute likelihood\n",
    "        likelihood = 0\n",
    "        for i in range(self.num_questions):\n",
    "            p = self.irt_3pl(theta=theta, a=a[i], b=b[i])\n",
    "            likelihood += np.sum(\n",
    "                self.response_matrix[:,i] * np.log(p) + \n",
    "                (1 - self.response_matrix[:,i]) * np.log(1 - p)\n",
    "            )\n",
    "        \n",
    "        return -likelihood\n",
    "    \n",
    "    def neg_log_likelihood_with_feasibility(self, params: np.array) -> float:\n",
    "        # Unpack parameters with additional gamma parameters\n",
    "        n_q = self.num_questions\n",
    "        a = params[:n_q]  # discrimination\n",
    "        b = params[n_q:2*n_q]  # difficulty\n",
    "        c = params[2*n_q:3*n_q]  # guessing\n",
    "        gamma = params[3*n_q:4*n_q]  # feasibility\n",
    "        theta = self.compute_theta(params[4*n_q:])\n",
    "        \n",
    "        # Compute likelihood with feasibility\n",
    "        likelihood = 0\n",
    "        for i in range(self.num_questions):\n",
    "            p = self.irt_3pl_with_feasibility(\n",
    "                theta=theta,\n",
    "                a=a[i],\n",
    "                b=b[i],\n",
    "                c=c[i],\n",
    "                gamma=gamma[i]\n",
    "            )\n",
    "            likelihood += np.sum(\n",
    "                self.response_matrix[:,i] * np.log(p) + \n",
    "                (1 - self.response_matrix[:,i]) * np.log(1 - p)\n",
    "            )\n",
    "        \n",
    "        return -likelihood\n",
    "    \n",
    "    def fit(self) -> Dict[str, np.array]:\n",
    "        \"\"\"Fit the IRT model using L-BFGS-B optimization\"\"\"\n",
    "        # Initial parameter guesses\n",
    "        initial_params = np.concatenate([\n",
    "            np.ones(self.num_questions),  # a (discrimination)\n",
    "            np.zeros(self.num_questions),  # b (difficulty)\n",
    "            np.zeros(self.num_llms + self.num_retrievers)  # theta components\n",
    "        ])\n",
    "        \n",
    "        # Parameter bounds\n",
    "        bounds = (\n",
    "            [(0.5, 1.5) for _ in range(self.num_questions)] +  # a bounds\n",
    "            [(0.01, 1.0) for _ in range(self.num_questions)] +  # b bounds\n",
    "            [(-3.0, 3.0) for _ in range(self.num_llms + self.num_retrievers)]  # theta bounds\n",
    "        )\n",
    "        \n",
    "        # Optimize\n",
    "        result = minimize(\n",
    "            self.neg_log_likelihood,\n",
    "            initial_params,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds\n",
    "        )\n",
    "        \n",
    "        # Extract parameters\n",
    "        params = {\n",
    "            'discrimination': result.x[:self.num_questions],\n",
    "            'difficulty': result.x[self.num_questions:2*self.num_questions],\n",
    "            'theta_params': result.x[2*self.num_questions:],\n",
    "            'theta': self.compute_theta(result.x[2*self.num_questions:])\n",
    "        }\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def fit_with_feasibility(self) -> Dict[str, np.array]:\n",
    "        \"\"\"Fit the IRT model using L-BFGS-B optimization\"\"\"\n",
    "        n_params = 4 * self.num_questions  # For a, b, c, and gamma\n",
    "        n_params += self.num_llms + self.num_retrievers  # For theta components\n",
    "        \n",
    "        initial_params = np.concatenate([\n",
    "            np.ones(self.num_questions),      # a (discrimination)\n",
    "            np.zeros(self.num_questions),     # b (difficulty)\n",
    "            0.25 * np.ones(self.num_questions),  # c (guessing)\n",
    "            0.8 * np.ones(self.num_questions),   # gamma (feasibility)\n",
    "            np.zeros(self.num_llms + self.num_retrievers)  # theta components\n",
    "        ])\n",
    "        \n",
    "        # Parameter bounds\n",
    "        bounds = (\n",
    "            [(0.2, 2.0) for _ in range(self.num_questions)] +  # a bounds\n",
    "            [(0.01, 1.0) for _ in range(self.num_questions)] +  # b bounds\n",
    "            [(0.0, 0.5) for _ in range(self.num_questions)] +  # c bounds\n",
    "            [(0.5, 1.0) for _ in range(self.num_questions)] +  # gamma bounds\n",
    "            [(-3.0, 3.0) for _ in range(self.num_llms + self.num_retrievers)]  # theta bounds\n",
    "        )\n",
    "        \n",
    "        # Optimize\n",
    "        result = minimize(\n",
    "            self.neg_log_likelihood_with_feasibility,\n",
    "            initial_params,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds\n",
    "        )\n",
    "        \n",
    "        # Extract parameters\n",
    "        params = {\n",
    "            'discrimination': result.x[:self.num_questions],\n",
    "            'difficulty': result.x[self.num_questions:2*self.num_questions],\n",
    "            'guessing': result.x[2*self.num_questions:3*self.num_questions],\n",
    "            'feasibility': result.x[3*self.num_questions:4*self.num_questions],\n",
    "            'theta_params': result.x[4*self.num_questions:],\n",
    "            'theta': self.compute_theta(result.x[4*self.num_questions:])\n",
    "            }\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def compute_information(self, params: Dict[str, np.array], theta: np.array) -> np.array:\n",
    "        \"\"\"Compute Fisher information for questions across ability levels\"\"\"\n",
    "        information = np.zeros((self.num_questions, len(theta)))\n",
    "        for i in range(self.num_questions):\n",
    "            a = params['discrimination'][i]\n",
    "            b = params['difficulty'][i]\n",
    "            c = params['guessing'][i]\n",
    "            gamma = params['feasibility'][i]\n",
    "            \n",
    "            # Compute probability\n",
    "            p = self.irt_3pl_with_feasibility(\n",
    "                theta=theta, \n",
    "                a=a, \n",
    "                b=b, \n",
    "                c=c, \n",
    "                gamma=gamma\n",
    "            )\n",
    "        \n",
    "            information[i] = (\n",
    "            (a**2 * (p - c)**2 * (1 - p)) / \n",
    "            ((gamma - c)**2 * p)\n",
    "        )\n",
    "        \n",
    "        return information\n",
    "    \n",
    "    def save_analysis(self, params: Dict[str, np.array], output_path: str):\n",
    "        \"\"\"Save analysis results to a JSON file\"\"\"\n",
    "        # Get unique hop counts\n",
    "        unique_hops = sorted(list(set(hop for result in self.exam_results for hop in result.num_hops)))\n",
    "        \n",
    "        # Calculate average difficulty and discrimination by hop count\n",
    "        hop_stats = {}\n",
    "        for hop_count in unique_hops:\n",
    "            # Get indices for questions with this hop count\n",
    "            indices = [i for i, hops in enumerate(self.exam_results[0].num_hops) if hops == hop_count]\n",
    "            \n",
    "            hop_stats[str(hop_count)] = {\n",
    "                \"avg_difficulty\": float(np.mean(params['difficulty'][indices])),\n",
    "                \"avg_discrimination\": float(np.mean(params['discrimination'][indices])),\n",
    "                \"avg_guessing\": float(np.mean(params['guessing'][indices])),\n",
    "                \"avg_feasibility\": float(np.mean(params['feasibility'][indices])),\n",
    "                \"num_questions\": len(indices)\n",
    "            }\n",
    "        \n",
    "        # Prepare model ability results\n",
    "        model_abilities = {}\n",
    "        for result in self.exam_results:\n",
    "            model_key = f\"{result.llm_name}\"\n",
    "            if result.retriever_name:\n",
    "                model_key += f\"_{result.retriever_name}\"\n",
    "            \n",
    "            idx = self.exam_results.index(result)\n",
    "            model_abilities[model_key] = float(params['theta'][idx])\n",
    "        \n",
    "        # Prepare component abilities\n",
    "        component_abilities = {\n",
    "            \"llms\": {\n",
    "                llm: float(params['theta_params'][idx])\n",
    "                for llm, idx in self.llm_map.items()\n",
    "            },\n",
    "            \"retrievers\": {\n",
    "                ret: float(params['theta_params'][self.num_llms + idx])\n",
    "                for ret, idx in self.retriever_map.items()\n",
    "            } if self.retriever_map else {}\n",
    "        }\n",
    "        \n",
    "        # Overall exam statistics\n",
    "        overall_stats = {\n",
    "            \"avg_difficulty\": float(np.mean(params['difficulty'])),\n",
    "            \"avg_discrimination\": float(np.mean(params['discrimination'])),\n",
    "            \"avg_guessing\": float(np.mean(params['guessing'][indices])),\n",
    "            \"avg_feasibility\": float(np.mean(params['feasibility'][indices])),\n",
    "            \"total_questions\": self.num_questions\n",
    "        }\n",
    "        \n",
    "        analysis_results = {\n",
    "            \"overall_stats\": overall_stats,\n",
    "            \"hop_analysis\": hop_stats,\n",
    "            \"model_abilities\": model_abilities,\n",
    "            \"component_abilities\": component_abilities,\n",
    "        }\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(analysis_results, f, indent=2)\n",
    "    \n",
    "    def plot_results(self, params: Dict[str, np.array], save_path: Optional[str] = None, title_prefix: str = \"\"):\n",
    "        \"\"\"Enhanced plot_results with new visualization functions\"\"\"\n",
    "        theta_range = np.linspace(-3, 3, 100)\n",
    "        \n",
    "        plt.style.use('seaborn-v0_8-poster')\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))\n",
    "        \n",
    "        # Item characteristic curves\n",
    "        for i in range(self.num_questions):\n",
    "            # p = self.irt_3pl(theta=theta_range, a=params['discrimination'][i], b=params['difficulty'][i])\n",
    "            p = self.irt_3pl_with_feasibility(\n",
    "                theta=theta_range,\n",
    "                a=params['discrimination'][i],\n",
    "                b=params['difficulty'][i],\n",
    "                c=params['guessing'][i],\n",
    "                gamma=params['feasibility'][i],\n",
    "                )\n",
    "            ax1.plot(theta_range, p, alpha=0.3, color='gray')\n",
    "        \n",
    "        # Use new plot_model_abilities for enhanced visualization\n",
    "        self.plot_model_abilities(ax1, theta_range, params, self.model_colors)\n",
    "        ax1.set_title(f'{title_prefix}Item Characteristic Curves\\nProbability of Correct Response vs. Ability')\n",
    "        ax1.set_xlabel('Model Ability (θ)')\n",
    "        ax1.set_ylabel('Probability of Correct Response')\n",
    "        \n",
    "        # Information curves\n",
    "        info = self.compute_information(params, theta_range)\n",
    "        for i in range(self.num_questions):\n",
    "            ax2.plot(theta_range, info[i], alpha=0.3, color='gray')\n",
    "        \n",
    "        # Use plot_model_abilities again for information curves\n",
    "        self.plot_model_abilities(ax2, theta_range, params, self.model_colors)\n",
    "        ax2.set_title(f'{title_prefix}Item Information Curves\\nMeasurement Precision Across Ability Levels')\n",
    "        ax2.set_xlabel('Model Ability (θ)')\n",
    "        ax2.set_ylabel('Information (Measurement Precision)')\n",
    "        \n",
    "        # Average information by hop count\n",
    "        self.plot_hop_information(ax3, info, theta_range)\n",
    "        \n",
    "        # Use new plot_component_abilities for enhanced visualization\n",
    "        self.plot_component_abilities(ax4, params)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_model_abilities(self, ax, theta_range, params, model_colors):\n",
    "        \"\"\"Plot model abilities with distinct colors\"\"\"\n",
    "        for i, (result, theta) in enumerate(zip(self.exam_results, params['theta'])):\n",
    "            label = f\"{result.llm_name}\"\n",
    "            if result.retriever_name:\n",
    "                label += f\" ({result.retriever_name})\"\n",
    "            \n",
    "            key = f\"{result.llm_name}_{result.retriever_name}\"\n",
    "            ax.scatter(theta, 0, marker='x', color=model_colors[key], \n",
    "                      s=100, label=label)\n",
    "        \n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "    def plot_component_abilities(self, ax, params):\n",
    "        \"\"\"Plot component abilities with stacked bars\"\"\"\n",
    "        llm_abilities = params['theta_params'][:self.num_llms]\n",
    "        ret_abilities = params['theta_params'][self.num_llms:]\n",
    "        \n",
    "        x = np.arange(self.num_llms)\n",
    "        width = 0.35\n",
    "        \n",
    "        # Create mapping of LLM names to their results\n",
    "        llm_results = {}\n",
    "        for result in self.exam_results:\n",
    "            if result.llm_name not in llm_results:\n",
    "                llm_results[result.llm_name] = []\n",
    "            llm_results[result.llm_name].append(result)\n",
    "        \n",
    "        # Plot LLM abilities\n",
    "        llm_bars = ax.bar(x, llm_abilities, width, label='LLM Base Ability',\n",
    "                        color='skyblue')\n",
    "        \n",
    "        # Plot retriever abilities as stacked bars\n",
    "        if self.num_retrievers > 0:\n",
    "            for llm_idx, (llm_name, results) in enumerate(llm_results.items()):\n",
    "                for result in results:\n",
    "                    if result.retriever_name:\n",
    "                        ret_idx = self.retriever_map[result.retriever_name]\n",
    "                        ax.bar(x[llm_idx], ret_abilities[ret_idx], width,\n",
    "                            bottom=llm_abilities[llm_idx],\n",
    "                            label=f'Retriever: {result.retriever_name}',\n",
    "                            color='lightgreen', alpha=0.7)\n",
    "        \n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([llm for llm in self.llm_map.keys()], rotation=45)\n",
    "        ax.set_title('Model Component Abilities')\n",
    "        ax.set_xlabel('Language Models')\n",
    "        ax.set_ylabel('Ability Parameter')\n",
    "        \n",
    "        # Remove duplicate labels in legend\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        ax.legend(by_label.values(), by_label.keys())\n",
    "    \n",
    "    def plot_hop_information(self, ax, info, theta_range):\n",
    "        \"\"\"Plot average information by hop count\"\"\"\n",
    "        unique_hops = np.unique(self.exam_results[0].num_hops)\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(unique_hops)))\n",
    "        \n",
    "        for hop_num, color in zip(unique_hops, colors):\n",
    "            hop_indices = [i for i, h in enumerate(self.exam_results[0].num_hops) \n",
    "                         if h == hop_num]\n",
    "            if hop_indices:\n",
    "                mean_info = info[hop_indices].mean(axis=0)\n",
    "                ax.plot(theta_range, mean_info, label=f'{hop_num} hops',\n",
    "                       color=color, linewidth=2)\n",
    "        \n",
    "        ax.set_title('Average Information by Hop Count')\n",
    "        ax.set_xlabel('Model Ability (θ)')\n",
    "        ax.set_ylabel('Average Information')\n",
    "        ax.legend(title='Number of Hops')\n",
    "\n",
    "\n",
    "def run_analysis(filepaths: Dict[str, Dict[str, Union[str, Dict[str, str]]]], \n",
    "                combine_exams: bool = False,\n",
    "                combine_exam_takers: bool = False,\n",
    "                output_dir: str = \"analysis_results\",\n",
    "                feasibility: bool = False\n",
    "                ):\n",
    "    \"\"\"Run IRT analysis with option to combine exam results\"\"\"\n",
    "    # Load and process exam results\n",
    "    exam_results = ExamResult.from_json_files(filepaths, combine_exams=combine_exams, combine_exam_takers=combine_exam_takers)\n",
    "    \n",
    "    # Initialize and fit the model\n",
    "    model = MultihopIRTModel(exam_results, num_questions=len(exam_results[0].responses))\n",
    "    if feasibility:\n",
    "        params = model.fit_with_feasibility()\n",
    "    else:\n",
    "        params = model.fit()\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save analysis results\n",
    "    analysis_type = \"combined\" if combine_exams else \"separate\"\n",
    "    model.save_analysis(params, output_dir / f\"{analysis_type}_analysis.json\")\n",
    "    \n",
    "    # Generate plots\n",
    "    model.plot_results(params, \n",
    "                      save_path=output_dir / f\"{analysis_type}_analysis_plots.png\",\n",
    "                      title_prefix=f\"{analysis_type.capitalize()} Exam Analysis: \")\n",
    "    \n",
    "    return model, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    task_domains = [\"gov_report\", \"hotpotqa\", \"multifieldqa_en\", \"SecFilings\", \"wiki\"]\n",
    "    exam_generators = [\"llama_3_2_3b\", \"gemma2_9b\", \"ministral_8b\"]\n",
    "    \n",
    "    # Analysis configurations\n",
    "    analysis_modes = [\n",
    "        {\"combine_exams\": True, \"combine_exam_takers\": False, \"output_suffix\": \"combined_takers\", \"feasibility\": True}\n",
    "        # {\"combine_exams\": False, \"combine_exam_takers\": False, \"output_suffix\": \"combined_takers\"}\n",
    "        # {\"combine_exams\": True, \"combine_exam_takers\": True, \"output_suffix\": \"combined_takers\"} - Don't use\n",
    "    ]\n",
    "    \n",
    "    for task_domain in task_domains:\n",
    "        print(f\"\\nProcessing task domain: {task_domain}\")\n",
    "        \n",
    "        for exam_generator in exam_generators:\n",
    "            print(f\"Processing exam generator: {exam_generator}\")\n",
    "            \n",
    "            # Define filepaths structure\n",
    "            filepaths = {\n",
    "                'llama3-8b': {\n",
    "                    # 'closed_book': {\n",
    "                    #     'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_closed_{exam_generator}_single_hop_exam_processed.json.json',\n",
    "                    #     'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_closed_exam_new_{exam_generator}_processed_v3.json.json'\n",
    "                    # },\n",
    "                    'DenseV3': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Dense_{exam_generator}_single_hop_exam_processed.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Dense_exam_new_{exam_generator}_processed_v3.json_5_results.json'\n",
    "                    },\n",
    "                    'DenseV4': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Dense_{exam_generator}_single_hop_exam_processed_v4.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Dense_exam_new_{exam_generator}_processed_v4.json_5_results.json'\n",
    "                    },\n",
    "                    'SparseV3': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Sparse_{exam_generator}_single_hop_exam_processed.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Sparse_exam_new_{exam_generator}_processed_v3.json_5_results.json'\n",
    "                    },\n",
    "                    'HybridV3': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Hybrid_{exam_generator}_single_hop_exam_processed.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Hybrid_exam_new_{exam_generator}_processed_v3.json_5_results.json'\n",
    "                    },\n",
    "                    'RerankV3': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Rerank_{exam_generator}_single_hop_exam_processed.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Rerank_exam_new_{exam_generator}_processed_v3.json_5_results.json'\n",
    "                    },\n",
    "                    'DenseV5-5': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Dense_{exam_generator}_single_hop_exam_processed_v5.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Dense_exam_new_{exam_generator}_processed_v5.json_5_results.json'\n",
    "                    },\n",
    "                    'SparseV5-5': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Sparse_{exam_generator}_single_hop_exam_processed_v5.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Sparse_exam_new_{exam_generator}_processed_v5.json_5_results.json'\n",
    "                    },\n",
    "                    'HybridV5-5': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Hybrid_{exam_generator}_single_hop_exam_processed_v5.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Hybrid_exam_new_{exam_generator}_processed_v5.json_5_results.json'\n",
    "                    },\n",
    "                    'RerankV5-5': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Rerank_{exam_generator}_single_hop_exam_processed_v5.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Rerank_exam_new_{exam_generator}_processed_v5.json_5_results.json'\n",
    "                    },\n",
    "                    'DenseV5-10': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Dense_{exam_generator}_single_hop_exam_processed_v5.json_10_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Dense_exam_new_{exam_generator}_processed_v5.json_10_results.json'\n",
    "                    },\n",
    "                    'SparseV5-10': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Sparse_{exam_generator}_single_hop_exam_processed_v5.json_10_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Sparse_exam_new_{exam_generator}_processed_v5.json_10_results.json'\n",
    "                    },\n",
    "                    'HybridV5-10': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Hybrid_{exam_generator}_single_hop_exam_processed_v5.json_10_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Hybrid_exam_new_{exam_generator}_processed_v5.json_10_results.json'\n",
    "                    },\n",
    "                    'RerankV5-10': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Rerank_{exam_generator}_single_hop_exam_processed_v5.json_10_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_Rerank_exam_new_{exam_generator}_processed_v5.json_10_results.json'\n",
    "                    },\n",
    "                    'open_book': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_open_{exam_generator}_single_hop_exam_processed.json.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/llama_3_1_8b_open_exam_new_{exam_generator}_processed_v3.json.json'\n",
    "                    },\n",
    "                },\n",
    "                'mistral-8b': {\n",
    "                    # 'closed_book': {\n",
    "                    #     'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_closed_{exam_generator}_single_hop_exam_processed.json.json',\n",
    "                    #     'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_closed_exam_new_{exam_generator}_processed_v3.json.json'\n",
    "                    # },\n",
    "                    'DenseV3': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Dense_{exam_generator}_single_hop_exam_processed.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Dense_exam_new_{exam_generator}_processed_v3.json_5_results.json'\n",
    "                    },\n",
    "                    'DenseV4': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Dense_{exam_generator}_single_hop_exam_processed_v4.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Dense_exam_new_{exam_generator}_processed_v4.json_5_results.json'\n",
    "                    },\n",
    "                    'SparseV3': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Sparse_{exam_generator}_single_hop_exam_processed.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Sparse_exam_new_{exam_generator}_processed_v3.json_5_results.json'\n",
    "                    },\n",
    "                    'HybridV3': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Hybrid_{exam_generator}_single_hop_exam_processed.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Hybrid_exam_new_{exam_generator}_processed_v3.json_5_results.json'\n",
    "                    },\n",
    "                    'RerankV3': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Rerank_{exam_generator}_single_hop_exam_processed.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Rerank_exam_new_{exam_generator}_processed_v3.json_5_results.json'\n",
    "                    },\n",
    "                    'DenseV5-5': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Dense_{exam_generator}_single_hop_exam_processed_v5.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Dense_exam_new_{exam_generator}_processed_v5.json_5_results.json'\n",
    "                    },\n",
    "                    'SparseV5-5': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Sparse_{exam_generator}_single_hop_exam_processed_v5.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Sparse_exam_new_{exam_generator}_processed_v5.json_5_results.json'\n",
    "                    },\n",
    "                    'HybridV5-5': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Hybrid_{exam_generator}_single_hop_exam_processed_v5.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Hybrid_exam_new_{exam_generator}_processed_v5.json_5_results.json'\n",
    "                    },\n",
    "                    'RerankV5-5': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Rerank_{exam_generator}_single_hop_exam_processed_v5.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Rerank_exam_new_{exam_generator}_processed_v5.json_5_results.json'\n",
    "                    },\n",
    "                    'DenseV5-10': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Dense_{exam_generator}_single_hop_exam_processed_v5.json_10_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Dense_exam_new_{exam_generator}_processed_v5.json_10_results.json'\n",
    "                    },\n",
    "                    'SparseV5-10': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Sparse_{exam_generator}_single_hop_exam_processed_v5.json_10_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Sparse_exam_new_{exam_generator}_processed_v5.json_10_results.json'\n",
    "                    },\n",
    "                    'HybridV5-10': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Hybrid_{exam_generator}_single_hop_exam_processed_v5.json_10_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Hybrid_exam_new_{exam_generator}_processed_v5.json_10_results.json'\n",
    "                    },\n",
    "                    'RerankV5-10': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Rerank_{exam_generator}_single_hop_exam_processed_v5.json_10_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_Rerank_exam_new_{exam_generator}_processed_v5.json_10_results.json'\n",
    "                    },\n",
    "                    'open_book': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_open_{exam_generator}_single_hop_exam_processed.json.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/ministral_8b_open_exam_new_{exam_generator}_processed_v3.json.json'\n",
    "                    },\n",
    "                },\n",
    "                'gemma2_9b': {\n",
    "                    'closed_book': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_closed_{exam_generator}_single_hop_exam_processed.json.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_closed_exam_new_{exam_generator}_processed_v3.json.json'\n",
    "                    },\n",
    "                    'DenseV3': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Dense_{exam_generator}_single_hop_exam_processed.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Dense_exam_new_{exam_generator}_processed_v3.json_5_results.json'\n",
    "                    },\n",
    "                    'DenseV4': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Dense_{exam_generator}_single_hop_exam_processed_v4.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Dense_exam_new_{exam_generator}_processed_v4.json_5_results.json'\n",
    "                    },\n",
    "                    'SparseV3': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Sparse_{exam_generator}_single_hop_exam_processed.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Sparse_exam_new_{exam_generator}_processed_v3.json_5_results.json'\n",
    "                    },\n",
    "                    'HybridV3': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Hybrid_{exam_generator}_single_hop_exam_processed.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Hybrid_exam_new_{exam_generator}_processed_v3.json_5_results.json'\n",
    "                    },\n",
    "                    'RerankV3': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Rerank_{exam_generator}_single_hop_exam_processed.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Rerank_exam_new_{exam_generator}_processed_v3.json_5_results.json'\n",
    "                    },\n",
    "                    'DenseV5-5': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Dense_{exam_generator}_single_hop_exam_processed_v5.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Dense_exam_new_{exam_generator}_processed_v5.json_5_results.json'\n",
    "                    },\n",
    "                    'SparseV5-5': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Sparse_{exam_generator}_single_hop_exam_processed_v5.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Sparse_exam_new_{exam_generator}_processed_v5.json_5_results.json'\n",
    "                    },\n",
    "                    'HybridV5-5': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Hybrid_{exam_generator}_single_hop_exam_processed_v5.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Hybrid_exam_new_{exam_generator}_processed_v5.json_5_results.json'\n",
    "                    },\n",
    "                    'RerankV5-5': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Rerank_{exam_generator}_single_hop_exam_processed_v5.json_5_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Rerank_exam_new_{exam_generator}_processed_v5.json_5_results.json'\n",
    "                    },\n",
    "                    'DenseV5-10': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Dense_{exam_generator}_single_hop_exam_processed_v5.json_10_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Dense_exam_new_{exam_generator}_processed_v5.json_10_results.json'\n",
    "                    },\n",
    "                    'SparseV5-10': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Sparse_{exam_generator}_single_hop_exam_processed_v5.json_10_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Sparse_exam_new_{exam_generator}_processed_v5.json_10_results.json'\n",
    "                    },\n",
    "                    'HybridV5-10': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Hybrid_{exam_generator}_single_hop_exam_processed_v5.json_10_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Hybrid_exam_new_{exam_generator}_processed_v5.json_10_results.json'\n",
    "                    },\n",
    "                    'RerankV5-10': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Rerank_{exam_generator}_single_hop_exam_processed_v5.json_10_results.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_Rerank_exam_new_{exam_generator}_processed_v5.json_10_results.json'\n",
    "                    },\n",
    "                    'open_book': {\n",
    "                        'single': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_open_{exam_generator}_single_hop_exam_processed.json.json',\n",
    "                        'multi': f'auto-rag-eval/MultiHopData/{task_domain}/exam_results/gemma2_9b_open_exam_new_{exam_generator}_processed_v3.json.json'\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Run analysis for each configuration\n",
    "            for analysis_config in analysis_modes:\n",
    "                output_dir = f\"analysis_results/{task_domain}/{exam_generator}/{analysis_config['output_suffix']}\"\n",
    "                print(f\"\\nRunning analysis with configuration:\")\n",
    "                print(f\"- Combine exams: {analysis_config['combine_exams']}\")\n",
    "                print(f\"- Combine exam takers: {analysis_config['combine_exam_takers']}\")\n",
    "                print(f\"- Feasibility: {analysis_config['feasibility']}\")\n",
    "                print(f\"- Output directory: {output_dir}\")\n",
    "                \n",
    "                try:\n",
    "                    model, params = run_analysis(\n",
    "                        filepaths=filepaths,\n",
    "                        combine_exams=analysis_config['combine_exams'],\n",
    "                        combine_exam_takers=analysis_config['combine_exam_takers'],\n",
    "                        output_dir=output_dir,\n",
    "                        feasibility=analysis_config[\"feasibility\"]\n",
    "                    )\n",
    "                    print(f\"Analysis completed successfully\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during analysis: {str(e)}\")\n",
    "                    continue\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
